"""Simple deep agent with model configuration from config file.

Model Configuration Priority:
1. model_config.json (from frontend Settings UI) - highest priority
2. Environment variables (OPENAI_API_KEY, OPENAI_MODEL, etc.)
3. Default fallback (Google Gemini)

Hot Reload: In dev mode, LangGraph's watchfiles will automatically reload
when model_config.json is modified by the frontend.

Model Override Support:
- Primary Model: Used for main chat
- Subagents (including general-purpose): Can use different models via model_overrides
- Summarization: Inherits from Primary Model (deepagents library limitation)
- Suggestions: Handled by frontend directly
"""

import json
import logging
import os
from datetime import datetime
from pathlib import Path
from typing import Any

from langchain.chat_models import init_chat_model
from langchain_core.language_models import BaseChatModel
from langchain_openai import ChatOpenAI

# Try to import AWS Bedrock support
try:
    from langchain_aws import ChatBedrock
    HAS_BEDROCK = True
except ImportError:
    HAS_BEDROCK = False
    ChatBedrock = None

from deepagents import create_deep_agent
from deepagents.middleware.subagents import DEFAULT_SUBAGENT_PROMPT

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# TODO: Setup automatic task logging (temporarily disabled due to LangGraph import issues)
# from deepagents.auto_task_logger import setup_auto_task_logging
# setup_auto_task_logging()

# Config file path (same directory as agent.py)
CONFIG_FILE = Path(__file__).parent / "model_config.json"


# ============================================================
# Configuration Functions
# ============================================================

def load_config_file() -> dict[str, Any] | None:
    """Load model configuration from JSON file.
    
    Returns:
        Configuration dict if file exists and is valid, None otherwise.
    """
    if not CONFIG_FILE.exists():
        logger.info(f"[MODEL CONFIG] Config file not found: {CONFIG_FILE}")
        return None
    
    try:
        with open(CONFIG_FILE, "r") as f:
            config = json.load(f)
        
        # Validate required fields
        if not config.get("provider") or not config.get("model"):
            logger.warning("[MODEL CONFIG] Config file missing provider or model")
            return None
        
        provider = config.get("provider")
        
        # Check credentials based on provider (config file only, no env var fallback)
        if provider == "bedrock":
            if not config.get("aws_access_key_id") or not config.get("aws_secret_access_key"):
                logger.warning("[MODEL CONFIG] AWS credentials not found in config file for Bedrock")
                return None
        elif provider == "azure":
            if not config.get("azure_api_key") or not config.get("azure_base_url"):
                logger.warning("[MODEL CONFIG] Azure credentials not found in config file")
                return None
        else:
            if not config.get("api_key"):
                logger.warning("[MODEL CONFIG] No API key found in config file")
                return None
        
        logger.info(f"[MODEL CONFIG] Loaded config from file: provider={provider}, model={config.get('model')}")
        return config
        
    except json.JSONDecodeError as e:
        logger.error(f"[MODEL CONFIG] Invalid JSON in config file: {e}")
        return None
    except Exception as e:
        logger.error(f"[MODEL CONFIG] Error reading config file: {e}")
        return None


def save_config_file(config: dict[str, Any]) -> bool:
    """Save model configuration to JSON file.
    
    This function is called by the frontend API to persist settings.
    
    Args:
        config: Configuration dict with provider, model, api_key, etc.
    
    Returns:
        True if saved successfully, False otherwise.
    """
    try:
        config["_last_updated"] = datetime.now().isoformat()
        config["_comment"] = "This file is auto-generated by the frontend. Edit via Settings UI."
        
        with open(CONFIG_FILE, "w") as f:
            json.dump(config, f, indent=2)
        
        logger.info(f"[MODEL CONFIG] Saved config to file: {CONFIG_FILE}")
        return True
        
    except Exception as e:
        logger.error(f"[MODEL CONFIG] Error saving config file: {e}")
        return False


# ============================================================
# Model Creation Functions
# ============================================================

def create_model_from_params(
    provider: str,
    model_name: str,
    api_key: str | None = None,
    base_url: str | None = None,
    label: str = "",
    # AWS Bedrock specific
    aws_access_key_id: str | None = None,
    aws_secret_access_key: str | None = None,
    aws_region: str | None = None,
    aws_account_id: str | None = None,
    # Azure specific
    azure_base_url: str | None = None,
    azure_api_key: str | None = None,
) -> BaseChatModel | None:
    """Create a model instance from parameters.
    
    Args:
        provider: Provider name (openai, anthropic, google, openrouter, bedrock, azure)
        model_name: Model name/ID
        api_key: API key (optional, falls back to env vars)
        base_url: Base URL for OpenAI-compatible APIs
        label: Label for logging (e.g., "Primary", "Subagent")
        aws_access_key_id: AWS Access Key ID for Bedrock
        aws_secret_access_key: AWS Secret Access Key for Bedrock
        aws_region: AWS Region for Bedrock
        aws_account_id: AWS Account ID for building Inference Profile ARN
        azure_base_url: Azure OpenAI base URL
        azure_api_key: Azure OpenAI API key
    
    Returns:
        Configured model instance, or None if creation fails.
    """
    log_prefix = f"[MODEL CONFIG] [{label}]" if label else "[MODEL CONFIG]"
    
    try:
        if provider == "openai":
            if api_key:
                logger.info(f"{log_prefix} Creating OpenAI model: {model_name}")
                return ChatOpenAI(model=model_name, openai_api_key=api_key)
            else:
                logger.warning(f"{log_prefix} OpenAI API key not configured in Settings")
        
        elif provider == "anthropic":
            if api_key:
                logger.info(f"{log_prefix} Creating Anthropic model: {model_name}")
                return init_chat_model(f"anthropic:{model_name}", api_key=api_key)
            else:
                logger.warning(f"{log_prefix} Anthropic API key not configured in Settings")
        
        elif provider == "google":
            if api_key:
                logger.info(f"{log_prefix} Creating Google model: {model_name}")
                return init_chat_model(f"google_genai:{model_name}", api_key=api_key)
            else:
                logger.warning(f"{log_prefix} Google API key not configured in Settings")
        
        elif provider == "openrouter":
            if api_key and base_url:
                logger.info(f"{log_prefix} Creating OpenAI-compatible model: {model_name} at {base_url}")
                return ChatOpenAI(
                    model=model_name,
                    openai_api_base=base_url,
                    openai_api_key=api_key,
                )
            else:
                logger.warning(f"{log_prefix} OpenAI-compatible API not fully configured in Settings")
        
        elif provider == "bedrock":
            if not HAS_BEDROCK:
                logger.error(f"{log_prefix} langchain-aws not installed. Run: pip install langchain-aws")
                return None
            
            if aws_access_key_id and aws_secret_access_key:
                region = aws_region or "us-east-1"
                
                actual_model_id = model_name
                if aws_account_id and not model_name.startswith("arn:"):
                    actual_model_id = f"arn:aws:bedrock:{region}:{aws_account_id}:inference-profile/us.{model_name}"
                    logger.info(f"{log_prefix} Built Inference Profile ARN: {actual_model_id}")
                
                logger.info(f"{log_prefix} Creating AWS Bedrock model: {actual_model_id} in {region}")
                bedrock_provider = None
                if "anthropic" in model_name.lower():
                    bedrock_provider = "anthropic"
                elif "amazon" in model_name.lower():
                    bedrock_provider = "amazon"
                elif "meta" in model_name.lower():
                    bedrock_provider = "meta"
                elif "mistral" in model_name.lower():
                    bedrock_provider = "mistral"
                elif "cohere" in model_name.lower():
                    bedrock_provider = "cohere"
                
                return ChatBedrock(
                    model_id=actual_model_id,
                    region_name=region,
                    credentials_profile_name=None,
                    model_kwargs={},
                    aws_access_key_id=aws_access_key_id,
                    aws_secret_access_key=aws_secret_access_key,
                    provider=bedrock_provider,
                )
            else:
                logger.warning(f"{log_prefix} AWS Bedrock credentials not configured in Settings")
        
        elif provider == "azure":
            if azure_base_url and azure_api_key:
                logger.info(f"{log_prefix} Creating Azure OpenAI model: {model_name} at {azure_base_url}")
                
                if "/openai/deployments/" in azure_base_url:
                    # Parse the full Azure URL to extract components
                    from urllib.parse import urlparse, parse_qs
                    parsed = urlparse(azure_base_url)
                    
                    # Extract api-version from query parameters
                    query_params = parse_qs(parsed.query)
                    api_version = query_params.get('api-version', ['2024-02-15-preview'])[0]
                    
                    # Extract base endpoint (without deployment path)
                    base_endpoint = f"{parsed.scheme}://{parsed.netloc}"
                    
                    logger.info(f"{log_prefix} Using Azure native client with endpoint: {base_endpoint}, api_version: {api_version}")
                    from langchain_openai import AzureChatOpenAI
                    return AzureChatOpenAI(
                        deployment_name=model_name,
                        azure_endpoint=base_endpoint,
                        api_key=azure_api_key,
                        api_version=api_version,
                    )
                else:
                    from langchain_openai import AzureChatOpenAI
                    return AzureChatOpenAI(
                        deployment_name=model_name,
                        azure_endpoint=azure_base_url,
                        api_key=azure_api_key,
                        api_version="2024-02-15-preview",
                    )
            else:
                logger.warning(f"{log_prefix} Azure OpenAI not fully configured in Settings")
        
        logger.warning(f"{log_prefix} Could not create model for provider={provider}. Please configure in Settings.")
        return None
        
    except Exception as e:
        logger.error(f"{log_prefix} Error creating model: {e}")
        return None


def get_model_from_config() -> BaseChatModel | None:
    """Get model from config file."""
    config = load_config_file()
    if not config:
        return None
    
    return create_model_from_params(
        provider=config.get("provider"),
        model_name=config.get("model"),
        api_key=config.get("api_key"),
        base_url=config.get("base_url"),
        label="Primary",
        aws_access_key_id=config.get("aws_access_key_id"),
        aws_secret_access_key=config.get("aws_secret_access_key"),
        aws_region=config.get("aws_region"),
        aws_account_id=config.get("aws_account_id"),
        azure_base_url=config.get("azure_base_url"),
        azure_api_key=config.get("azure_api_key"),
    )


def get_model_from_env() -> BaseChatModel | None:
    """Get model from environment variables (deprecated, only for debugging)."""
    model_name = os.environ.get("MODEL_NAME")
    if model_name:
        logger.info(f"[MODEL CONFIG] Using MODEL_NAME from env (debug): {model_name}")
        return init_chat_model(model_name)
    return None


def get_default_model() -> BaseChatModel:
    """Get the default model with priority: config file > env vars > fallback."""
    model = get_model_from_config()
    if model:
        return model
    
    model = get_model_from_env()
    if model:
        return model
    
    # Return a placeholder model that will be configured by user in Settings UI
    logger.warning("[MODEL CONFIG] No config found. Please configure AI model in Settings UI.")
    logger.warning("[MODEL CONFIG] Using placeholder model - agent will not work until configured.")
    # Return a minimal ChatOpenAI instance without API key (will fail gracefully when used)
    return ChatOpenAI(model="gpt-4", api_key="placeholder_key_configure_in_settings", temperature=0)


# ============================================================
# Subagent Model Configuration
# ============================================================

def get_subagent_model(subagent_name: str, primary_model: BaseChatModel) -> BaseChatModel:
    """Get model for a specific subagent."""
    config = load_config_file()
    if not config:
        return primary_model
    
    model_overrides = config.get("model_overrides", {})
    subagent_overrides = model_overrides.get("subagents", {})
    override_model = subagent_overrides.get(subagent_name)
    
    if not override_model:
        logger.info(f"[MODEL CONFIG] [Subagent:{subagent_name}] Inheriting from Primary")
        return primary_model
    
    logger.info(f"[MODEL CONFIG] [Subagent:{subagent_name}] Using override: {override_model}")
    
    subagent_model = create_model_from_params(
        provider=config.get("provider"),
        model_name=override_model,
        api_key=config.get("api_key"),
        base_url=config.get("base_url"),
        label=f"Subagent:{subagent_name}",
        aws_access_key_id=config.get("aws_access_key_id"),
        aws_secret_access_key=config.get("aws_secret_access_key"),
        aws_region=config.get("aws_region"),
        aws_account_id=config.get("aws_account_id"),
        azure_base_url=config.get("azure_base_url"),
        azure_api_key=config.get("azure_api_key"),
    )
    
    return subagent_model if subagent_model else primary_model


def build_custom_subagents(primary_model: BaseChatModel) -> list[dict[str, Any]]:
    """Build custom subagents with model overrides."""
    subagents = []
    
    gp_model = get_subagent_model("general-purpose", primary_model)
    
    if gp_model is not primary_model:
        subagents.append({
            "name": "general-purpose",
            "description": "General purpose subagent for complex, multi-step tasks. Has access to all tools.",
            "system_prompt": DEFAULT_SUBAGENT_PROMPT,
            "model": gp_model,
            "tools": [],
        })
        logger.info("[MODEL CONFIG] Created custom general-purpose subagent with different model")
    else:
        logger.info("[MODEL CONFIG] Using default general-purpose subagent (same model as primary)")
    
    return subagents


# ============================================================
# Agent Initialization
# ============================================================

print("=" * 60)
print("AGENT.PY LOADING")
print(f"  Config file: {CONFIG_FILE}")
print(f"  Config exists: {CONFIG_FILE.exists()}")
print("=" * 60)

# Create primary model from config file or environment
default_model = get_default_model()

# Build custom subagents with model overrides
custom_subagents = build_custom_subagents(default_model)

# Import tools from local tools package
from tools import (
    get_builtin_tools,
    get_serp_tools,
    get_exa_tools,
    get_tavily_tools,
    get_perplexity_tools,
    get_semrush_tools,
    get_serper_tools,
    get_report_tools,
)

# Get all tools
builtin_tools = get_builtin_tools()
serp_tools = get_serp_tools()
exa_tools = get_exa_tools()
tavily_tools = get_tavily_tools()
perplexity_tools = get_perplexity_tools()
semrush_tools = get_semrush_tools()
serper_tools = get_serper_tools()
report_tools = get_report_tools()

# Combine all tools
all_tools = (
    builtin_tools +
    serp_tools +
    exa_tools +
    tavily_tools +
    perplexity_tools +
    semrush_tools +
    serper_tools +
    report_tools
)

# Tools for Phase 1-6 (no report generation tools)
analysis_tools = (
    builtin_tools +
    serp_tools +
    exa_tools +
    tavily_tools +
    perplexity_tools +
    semrush_tools +
    serper_tools
)

# Create the base agent (for normal chat - has all tools)
base_agent = create_deep_agent(
    model=default_model,
    tools=all_tools if all_tools else None,
    system_prompt="You are a helpful AI assistant. Be concise and helpful in your responses.",
    subagents=custom_subagents if custom_subagents else None,
)

# Create analysis agent for Phase 1-6 (no report tools to prevent premature report generation)
analysis_agent = create_deep_agent(
    model=default_model,
    tools=analysis_tools if analysis_tools else None,
    system_prompt="You are a helpful AI assistant. Be concise and helpful in your responses.",
    subagents=custom_subagents if custom_subagents else None,
)

# Create report agent for Phase 7 (has report tools)
report_agent = create_deep_agent(
    model=default_model,
    tools=all_tools if all_tools else None,
    system_prompt="You are a helpful AI assistant. Be concise and helpful in your responses.",
    subagents=custom_subagents if custom_subagents else None,
)

logger.info("[MODEL CONFIG] Agent created successfully")
print("=" * 60)
print("AGENT READY")
print(f"  Primary Model: {default_model}")
print(f"  Custom Subagents: {len(custom_subagents)}")

# Display tools status
if builtin_tools:
    print(f"  Built-in Tools: {len(builtin_tools)} enabled")
if serp_tools:
    print(f"  SerpAPI Tools: {len(serp_tools)} enabled")
if exa_tools:
    print(f"  Exa Tools: {len(exa_tools)} enabled")
if tavily_tools:
    print(f"  Tavily Tools: {len(tavily_tools)} enabled")
if perplexity_tools:
    print(f"  Perplexity Tools: {len(perplexity_tools)} enabled")
if semrush_tools:
    print(f"  Semrush Tools: {len(semrush_tools)} enabled")
if serper_tools:
    print(f"  Serper Tools: {len(serper_tools)} enabled")
if report_tools:
    print(f"  Report Tools: {len(report_tools)} enabled")

print(f"  Total Tools: {len(all_tools)}")
print("=" * 60)

# ============================================================
# Playbook Support - Import Phase Executors
# ============================================================

from playbooks.state import create_initial_state
from playbooks.phases import (
    execute_phase_1,
    execute_phase_2,
    execute_phase_3,
    execute_phase_4,
    execute_phase_5,
    execute_phase_6,
    execute_phase_7,
)


# ============================================================
# Smart Router: Playbook vs Normal Chat (Flat Architecture)
# ============================================================

from langgraph.graph import StateGraph, END, START
from typing_extensions import TypedDict
from langchain_core.messages import HumanMessage, AIMessage

# Import playbook components
from playbooks.state import create_initial_state
from playbooks.phases import (
    execute_phase_1,
    execute_phase_2,
    execute_phase_3,
    execute_phase_4,
    execute_phase_5,
    execute_phase_6,
    execute_phase_7,
)

class UnifiedState(TypedDict):
    """Unified state supporting both normal chat and playbook execution."""
    # Core fields
    messages: list
    todos: list  # Task tracking for UI display
    files: dict  # Artifacts/files generated during execution (for UI display)
    
    # Playbook fields (optional, only used when executing playbook)
    playbook_id: str | None
    competitor_domains: list[str] | None
    my_domain: str | None
    primary_market: str | None
    
    # Phase results
    phase1_overview: dict | None
    phase2_history: dict | None
    phase3_content: dict | None
    phase4_gaps: dict | None
    phase5_benchmark: dict | None
    phase6_investigation: dict | None
    phase7_report: dict | None
    
    # Execution tracking
    phases_completed: list[int] | None
    current_phase: int | None
    errors: list | None
    final_report_path: str | None

def is_playbook_request(state: UnifiedState) -> str:
    """Detect if message is a playbook request.
    
    Returns:
        "playbook_init" if playbook request, otherwise "agent"
    """
    if not state.get('messages'):
        return "agent"
    
    last_message = state['messages'][-1]
    
    if isinstance(last_message, dict):
        content = last_message.get('content', '')
    else:
        content = getattr(last_message, 'content', '')
    
    if content.strip().startswith("Execute playbook:"):
        logger.info("[ROUTER] Detected playbook request")
        return "playbook_init"
    else:
        return "agent"

def playbook_init_node(state: UnifiedState) -> UnifiedState:
    """Initialize playbook execution and send acknowledgment."""
    logger.info("[PLAYBOOK INIT] Parsing playbook request")
    
    # Extract and parse playbook request
    user_messages = [m for m in state['messages'] if not isinstance(m, AIMessage)]
    if not user_messages:
        logger.error("[PLAYBOOK INIT] No user message found")
        return state
    
    last_message = user_messages[-1]
    if isinstance(last_message, dict):
        message_content = last_message.get('content', '')
    else:
        message_content = getattr(last_message, 'content', '')
    
    # Parse playbook parameters
    lines = message_content.strip().split('\n')
    playbook_title = lines[0].replace("Execute playbook:", "").strip()
    
    # Map title to playbook_id
    playbook_mapping = {
        "Competitor SEO Growth Engine Audit": "competitor-growth-engine-audit",
    }
    
    playbook_id = playbook_mapping.get(playbook_title)
    
    if not playbook_id:
        logger.warning(f"[PLAYBOOK INIT] Unknown playbook: {playbook_title}")
        state['messages'].append(AIMessage(content=f"❌ Unknown playbook: {playbook_title}"))
        return state
    
    # Parse parameters
    params = {}
    current_key = None
    current_list = []
    
    for line in lines[1:]:
        line = line.strip()
        if not line:
            continue
        
        if ':' in line and not line.startswith(('1.', '2.', '3.')):
            if current_key and current_list:
                params[current_key] = current_list
                current_list = []
            
            key, value = line.split(':', 1)
            key = key.strip()
            value = value.strip()
            
            if value:
                params[key] = value
                current_key = None
            else:
                current_key = key
        
        elif line.startswith(('1.', '2.', '3.', '4.', '5.')):
            item = line.split('.', 1)[1].strip()
            current_list.append(item)
    
    if current_key and current_list:
        params[current_key] = current_list
    
    # Initialize playbook state
    state['playbook_id'] = playbook_id
    state['competitor_domains'] = params.get('competitor_domains', [])
    state['my_domain'] = params.get('my_domain')
    state['primary_market'] = params.get('primary_market', 'us')
    state['phases_completed'] = []
    state['current_phase'] = 1
    state['errors'] = []
    state['todos'] = []  # Initialize todos for task tracking
    state['files'] = {}  # Initialize files for artifacts display
    state['phase1_overview'] = None
    state['phase2_history'] = None
    state['phase3_content'] = None
    state['phase4_gaps'] = None
    state['phase5_benchmark'] = None
    state['phase6_investigation'] = None
    state['phase7_report'] = None
    state['final_report_path'] = None
    
    logger.info(f"[PLAYBOOK INIT] Initialized: {playbook_id}")
    logger.info(f"[PLAYBOOK INIT] Parameters: {params}")
    
    # Format competitor list
    competitor_list = "\n".join([f"  - {d}" for d in state['competitor_domains']])
    my_domain_display = state['my_domain'] if state['my_domain'] else "Not provided"
    
    # Send acknowledgment with professional English message
    state['messages'].append(AIMessage(content=f"""**Competitor SEO Growth Engine Audit**

Initiating comprehensive competitive analysis...

**Target Configuration**
| Parameter | Value |
|-----------|-------|
| Your Domain | `{my_domain_display}` |
| Target Market | {state['primary_market'].upper()} |
| Competitors | {len(state['competitor_domains'])} domain(s) |

**Competitors to Analyze**
{competitor_list}

**Execution Pipeline**

| Phase | Analysis | Description |
|-------|----------|-------------|
| 1 | Batch Overview | Traffic, authority, and core SEO metrics |
| 2 | Historical Trends | 12-month traffic patterns & fluctuations |
| 3 | Content & Technical | Content structure, technical SEO, UX signals |
| 4 | Keyword Gap | Competitive keyword opportunities |
| 5 | Benchmark | Performance vs industry standards |
| 6 | Root Cause | Deep investigation (if anomalies detected) |
| 7 | Report | Executive summary & actionable insights |

---
"""))
    
    return state

def execute_agent_node(state: UnifiedState) -> UnifiedState:
    """Execute normal agent."""
    logger.info("[AGENT NODE] Executing normal agent")
    
    # Call base agent
    result = base_agent.invoke({'messages': state['messages']})
    
    # Merge messages back
    state['messages'] = result['messages']
    
    return state

def should_execute_phase_6(state: UnifiedState) -> str:
    """Check if Phase 6 (Root Cause Investigation) is needed.
    
    Returns:
        "phase_6" if investigation required, otherwise "phase_7" (skip to report)
    """
    phase2_data = state.get('phase2_history')
    
    # Handle case where phase2_data is None or not a dict (e.g., phase 2 failed)
    if phase2_data is None or not isinstance(phase2_data, dict):
        logger.info("[ROUTER] Phase 2 data unavailable → Skipping Phase 6")
        return "phase_7"  # Skip Phase 6, go directly to Phase 7
    
    if phase2_data.get('requires_investigation', False):
        logger.info("[ROUTER] Phase 2 detected fluctuations → Routing to Phase 6")
        return "phase_6"
    else:
        logger.info("[ROUTER] No fluctuations → Skipping Phase 6")
        return "phase_7"  # Skip Phase 6, go directly to Phase 7

# Create base agent
base_agent = create_deep_agent(
    model=default_model,
    tools=all_tools if all_tools else None,
    system_prompt="You are a helpful AI assistant. Be concise and helpful in your responses.",
    subagents=custom_subagents if custom_subagents else None,
)

# ============================================================
# Build Flat Router with Embedded Phase Nodes
# ============================================================

router = StateGraph(UnifiedState)

# Add normal agent node
router.add_node("agent", execute_agent_node)

# Add playbook init node
router.add_node("playbook_init", playbook_init_node)

# Create phase node wrappers
# Phase 1-6 use analysis_agent (no report tools to prevent premature report generation)
# Phase 7 uses report_agent (has report tools)
def phase_1_node(state: UnifiedState) -> UnifiedState:
    """Execute Phase 1 with analysis agent (no report tools)."""
    logger.info("[PHASE 1 NODE] Starting")
    return execute_phase_1(state, analysis_agent)

def phase_2_node(state: UnifiedState) -> UnifiedState:
    """Execute Phase 2 with analysis agent (no report tools)."""
    logger.info("[PHASE 2 NODE] Starting")
    return execute_phase_2(state, analysis_agent)

def phase_3_node(state: UnifiedState) -> UnifiedState:
    """Execute Phase 3 with analysis agent (no report tools)."""
    logger.info("[PHASE 3 NODE] Starting")
    return execute_phase_3(state, analysis_agent)

def phase_4_node(state: UnifiedState) -> UnifiedState:
    """Execute Phase 4 with analysis agent (no report tools)."""
    logger.info("[PHASE 4 NODE] Starting")
    return execute_phase_4(state, analysis_agent)

def phase_5_node(state: UnifiedState) -> UnifiedState:
    """Execute Phase 5 with analysis agent (no report tools)."""
    logger.info("[PHASE 5 NODE] Starting")
    return execute_phase_5(state, analysis_agent)

def phase_6_node(state: UnifiedState) -> UnifiedState:
    """Execute Phase 6 with analysis agent (no report tools)."""
    logger.info("[PHASE 6 NODE] Starting")
    return execute_phase_6(state, analysis_agent)

def phase_7_node(state: UnifiedState) -> UnifiedState:
    """Execute Phase 7 with report agent (has report tools for final report generation)."""
    logger.info("[PHASE 7 NODE] Starting")
    result = execute_phase_7(state, report_agent)
    
    # Add completion message
    phase7_data = result.get('phase7_report', {})
    if phase7_data.get('raw_output'):
        result['messages'].append(AIMessage(content=f"""✅ **Playbook Complete!**

**Phases Executed:** {result['phases_completed']}
**Errors:** {len(result.get('errors', []))}

---

{phase7_data['raw_output'][:10000]}
"""))
    
    return result

# Add all phase nodes
router.add_node("phase_1", phase_1_node)
router.add_node("phase_2", phase_2_node)
router.add_node("phase_3", phase_3_node)
router.add_node("phase_4", phase_4_node)
router.add_node("phase_5", phase_5_node)
router.add_node("phase_6", phase_6_node)
router.add_node("phase_7", phase_7_node)

# ============================================================
# Define Router Edges
# ============================================================

# Entry point: route to playbook or normal agent
router.add_conditional_edges(
    START,
    is_playbook_request,
    {
        "playbook_init": "playbook_init",
        "agent": "agent",
    }
)

# Playbook flow: init → phase_1 → phase_2 → phase_3 → phase_4 → phase_5
router.add_edge("playbook_init", "phase_1")
router.add_edge("phase_1", "phase_2")
router.add_edge("phase_2", "phase_3")
router.add_edge("phase_3", "phase_4")
router.add_edge("phase_4", "phase_5")

# After phase_5, conditionally execute phase_6 or skip to phase_7
router.add_conditional_edges(
    "phase_5",
    should_execute_phase_6,
    {
        "phase_6": "phase_6",
        "phase_7": "phase_7",
    }
)

# Phase_6 flows to phase_7
router.add_edge("phase_6", "phase_7")

# End nodes
router.add_edge("phase_7", END)
router.add_edge("agent", END)

# Compile router
agent = router.compile()

logger.info("[ROUTER] ✅ Flat architecture configured - all phases are top-level nodes")
print("[ROUTER] ✅ Each phase will stream tool calls to frontend")
